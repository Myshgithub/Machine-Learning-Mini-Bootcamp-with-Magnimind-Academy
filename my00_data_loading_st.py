# -*- coding: utf-8 -*-
"""My00 - Data Loading-St.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gJBaz6YQuTN5SgRxBgvqvuDqbQm3fKom

# Data Loading

## Data loading with Pandas
"""

import pandas as pd

# subset of the 1993 US census
data = pd.read_csv("sample_data/adult.csv", index_col=0)
data0 = pd.read_csv("sample_data/adult.csv")

#Run this cell to mount your Google Drive.
#from google.colab import drive
#drive.mount('/content/drive')

data.head()

data0.tail()

data

"""## Simple analysis"""

data.shape

data.columns

#counting number of unique values in income column
data.income.value_counts()

data0.income.value_counts()

D1=data.groupby("income").count()
#type(D1)
D1

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
data.groupby("income").age.hist()

"""# Splitting into training and test data"""

X = data.drop("income", axis=1) #Whether to drop labels from the index (0 or ‘index’) or columns (1 or ‘columns’)
y = data.income

X.head()

y.head()

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y) #default is 25-75 split

X_train.head()

X_train.shape

"""# Exercise I 
Load the "boston house prices" dataset from the ``boston_house_prices.csv`` file using the ``pd.read_csv`` function (you don't need ``index_column`` here).
You can find a description of this dataset in the ``boston_house_prices.txt`` file.

This is a regression dataset with "MEDV" the median house value in a block in thousand dollars the target.
How many features are there and how many samples?

Split the data into a training and a test set for learning.
Optionally you can plot MEDV vs any of the features using the ``plot`` method of the dataframe (using ``kind="scatter"``).
"""

import pandas as pd
from sklearn.model_selection import train_test_split

bdata = pd.read_csv("sample_data/boston_house_prices.csv")
bdata

print("Number of observations/samples: {}, Number of Features: {}".format(bdata.shape[0],bdata.shape[1]))

bdata.shape[0]

bdata.columns
print("boston house prices dataset Columns are: {}" .format(bdata.columns))

#Split the data into a training and a test set for learning.
bx=bdata.drop("MEDV",axis=1)
bx

by=bdata.MEDV
by.head()

bx_train, bx_test, by_train, by_test = train_test_split(bx,by)

bx_train.shape

bx_test.shape

import matplotlib as plt

bdata.plot.scatter(x="CRIM", y="MEDV",)

bdata.plot("RM","MEDV",kind="scatter")

"""## Load Datasets from ScikitLearn

Get some data to play with
"""

from sklearn.datasets import load_digits
import numpy as np
digits = load_digits()
digits.keys()

digits

type(digits)

digits.data

digits['DESCR']

digits.data.shape

digits.target.shape

#64 features for each digit we have

digits.target

np.bincount(digits.target)   #Cool Method

digits.data[0].shape

digits.data[0].reshape(8, 8).shape

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline
# %matplotlib notebook <- interactive interface
#plt.matshow: Display an array as a matrix in a new figure window.
plt.matshow(digits.data[0].reshape(8, 8), cmap=plt.cm.Greys)  #Color Map Gray
plt.matshow(digits.data[0].reshape(8, 8), cmap=plt.cm.Blues)  #Color Map Blue
plt.imshow(digits.data[0].reshape(8, 8), cmap=plt.cm.Greys)
plt.imshow(digits.data[1].reshape(8,8), cmap=plt.cm.OrRd)

digits.target[0]

'''
plt.subplots() is a function that returns a tuple containing a
figure and axes object(s). Thus when using fig, ax = plt.subplots()
you unpack this tuple into the variables fig and ax. Having fig is
useful if you want to change figure-level attributes or save the
figure as an image file later (e.g. with fig.savefig('yourfilename.png')).
'''

fig, axes = plt.subplots(4, 4)
for x, y, ax in zip(digits.data, digits.target, axes.ravel()):
    #ax.set_title(y) #Set a title for the axes.
    ax.imshow(x.reshape(8, 8), cmap="gray_r") #Display an image, i.e. data on a 2D regular raster.
    #ax.set_xticks(())#Set the xaxis' tick locations.
    #ax.set_yticks(())
#plt.tight_layout()

"""**Data is always a numpy array (or sparse matrix) of shape (n_samples, n_features)**

Split the data to get going
"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(digits.data,
                                                    digits.target, test_size=0.25, random_state=1)

digits.data.shape

X_train.shape

X_test.shape



"""# Exercise II

Load the iris dataset from the ``sklearn.datasets`` module using the ``load_iris`` function.
The function returns a dictionary-like object that has the same attributes as ``digits``.

What is the number of classes, features and data points in this dataset?
Use a scatterplot to visualize the dataset.

You can look at ``DESCR`` attribute to learn more about the dataset.
"""

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
irdata = load_iris()

irdata

irdata.keys()

irdata.data[0]

irdata.target

irdata.target.shape

np.bincount(irdata.target)

x=irdata.data
x

y=irdata.target
y

np.unique(y)

#Print

x_train, x_test, y_train, y_test =train_test_split(x,y)

import matplotlib.pyplot as plt

plt.scatter(x=x_train[:,0],y=x_train[:,1],s=30*x_train[:,3] ,c=y_train) #Adding Third feature with size 30 times